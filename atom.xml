<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>sangplus的博客</title>
  
  
  <link href="http://sangplus.com.cn/atom.xml" rel="self"/>
  
  <link href="http://sangplus.com.cn/"/>
  <updated>2023-03-16T03:19:17.589Z</updated>
  <id>http://sangplus.com.cn/</id>
  
  <author>
    <name>SangPlus</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>sentence-transformers详解</title>
    <link href="http://sangplus.com.cn/2023/03/15/sentence-transformers%E8%AF%A6%E8%A7%A3/"/>
    <id>http://sangplus.com.cn/2023/03/15/sentence-transformers%E8%AF%A6%E8%A7%A3/</id>
    <published>2023-03-15T06:07:55.000Z</published>
    <updated>2023-03-16T03:19:17.589Z</updated>
    
    <content type="html"><![CDATA[<p>从基础的bert构建一个sentence-transformer模型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sentence_transformers <span class="keyword">import</span> SentenceTransformer, models</span><br><span class="line"></span><br><span class="line">model_path = <span class="string">&quot;/Users/sang/workhome/pretrained_models/pytorch/pytorch_bert&quot;</span></span><br><span class="line"></span><br><span class="line">word_embedding_model = models.Transformer(model_path, max_seq_length=<span class="number">256</span>)</span><br><span class="line">pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())</span><br><span class="line"></span><br><span class="line">model = SentenceTransformer(modules=[word_embedding_model, pooling_model])</span><br><span class="line"></span><br><span class="line">sentences = [<span class="string">&#x27;This framework generates embeddings for each input sentence&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Sentences are passed as a list of string.&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;The quick brown fox jumps over the lazy dog.&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#Sentences are encoded by calling model.encode()</span></span><br><span class="line">embeddings = model.encode(sentences)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(embeddings.shape)</span><br><span class="line"><span class="built_in">print</span>(embeddings.dtype)</span><br></pre></td></tr></table></figure><p>准备训练数据，用到InputExample模块</p><script type="text&#x2F;javascript" src="https://unpkg.com/kity@2.0.4/dist/kity.min.js"></script><script type="text&#x2F;javascript" src="https://unpkg.com/kityminder-core@1.4.50/dist/kityminder.core.min.js"></script><script defer="true" type="text&#x2F;javascript" src="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.js"></script><link rel="stylesheet" type="text&#x2F;css" href="https://unpkg.com/hexo-simple-mindmap@0.8.0/dist/mindmap.min.css">]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;从基础的bert构建一个sentence-transformer模型&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br</summary>
      
    
    
    
    
    <category term="预训练模型" scheme="http://sangplus.com.cn/tags/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/"/>
    
    <category term="NLP" scheme="http://sangplus.com.cn/tags/NLP/"/>
    
  </entry>
  
</feed>
